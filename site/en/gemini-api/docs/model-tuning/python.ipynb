{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Model tuning with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs/model-tuning/python\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  </td>\n",
        "    <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/model-tuning/python.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/model-tuning/python.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp_CKyzxUqx6"
      },
      "source": [
        "In this notebook, you'll learn how to get started with the tuning service using the Python client library for the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOz_wyZAlCuQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHimx8NGMWDj"
      },
      "source": [
        "### Install the client library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cbcf72bcb56d"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdIYSl2kN0cq"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8enrppafJPCX"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lhqVUjH7ZKUi"
      },
      "outputs": [],
      "source": [
        "# @title Default title text\n",
        "from google.colab import userdata\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configure Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'GOOGLE_API_KEY'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://aistudio.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://aistudio.google.com/app/apikey\")\n",
        "  raise e"
      ],
      "metadata": {
        "id": "yVjDaYqtPie3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Connect to the API and send an example message\n",
        "\n",
        "text = 'What is the velocity of an unladen swallow?' # @param {type: \"string\"}\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "response = chat.send_message(text)\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "j5LHpEQdPie3",
        "outputId": "3cb3e871-9d47-4eaa-e840-c1b00fc36e3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ah, the classic unladen swallow question! The answer, as with most things, is not so simple. It depends:\\n\\n**The Core Problem:**\\n\\n*   **What kind of swallow?** There are many species of swallow (Barn swallow, European swallow, African swallow, etc.) and they have different flight characteristics.\\n*   **\"Unladen\" is vague:** What constitutes \"unladen\"? Is it just the bird itself, or are we considering things like atmospheric conditions, wind speed, etc.?\\n\\n**The Famous Monty Python Scene:**\\n\\nThis question comes from the Monty Python sketch \"Monty Python and the Holy Grail.\" In the sketch, the answer is crucial to crossing the Bridge of Death. The characters debate the following:\\n\\n*   **King Arthur asks:** \"What... is the air-speed velocity of an unladen swallow?\"\\n*   **A Guard replies:** \"What do you mean? An African or European swallow?\"\\n\\n**Possible Answers (based on real science and the Monty Python debate):**\\n\\n1.  **European Swallow:**\\n    *   Based on scientific studies of European swallows, the air-speed velocity of an unladen European swallow is roughly **11 meters per second, or about 24 miles per hour**. This is a rough estimate, and can vary due to wind conditions, and other factors.\\n\\n2.  **African Swallow:**\\n    *   This is where it gets really tricky. We don\\'t have a precise scientific answer, and the joke is that we don\\'t know. One could speculate it might be faster, as one might assume African swallows are able to carry more load, or perhaps the African swallow has different flying techniques that make it slower or faster.\\n\\n**In Conclusion:**\\n\\n*   The \"correct\" answer is partially a joke and depends on the kind of swallow.\\n*   For a *European* swallow, roughly 11 m/s or 24 mph is a reasonable estimate.\\n*   The question is more about highlighting the absurdity of precise answers to vague questions.\\n* The Monty Python scene also satirizes pedantry.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-MYZECwlRCq"
      },
      "source": [
        "You can check you existing tuned models with the `genai.list_tuned_model` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XyWzoYFxU4r6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b4856a-9760-4959-8abc-882b943b967e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tunedModels/generate-num-8885\n"
          ]
        }
      ],
      "source": [
        "for i, m in zip(range(5), genai.list_tuned_models()):\n",
        "  print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhkXRzciv3Dp"
      },
      "source": [
        "## Create tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8VZYAinLWc"
      },
      "source": [
        "To create a tuned model, you need to pass your dataset to the model in the `genai.create_tuned_model` method. You can do this be directly defining the input and output values in the call or importing from a file into a dataframe to pass to the method.\n",
        "\n",
        "For this example, you will tune a model to generate the next number in the sequence. For example, if the input is `1`, the model should output `2`. If the input is `one hundred`, the output should be `one hundred one`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w-EBSe9wTbLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "da79cf08-f1e3-4697-d0a7-d671b956e316"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "      base_model_id='',\n",
              "      version='001',\n",
              "      display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "      description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                   'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "      input_token_limit=16384,\n",
              "      output_token_limit=8192,\n",
              "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "      temperature=1.0,\n",
              "      max_temperature=2.0,\n",
              "      top_p=0.95,\n",
              "      top_k=64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "base_model = [\n",
        "    m for m in genai.list_models()\n",
        "    if \"createTunedModel\" in m.supported_generation_methods and\n",
        "    \"flash\" in m.name][0]\n",
        "base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "baHjHh1oTTTC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "name = f'generate-num-{random.randint(0,10000)}'\n",
        "operation = genai.create_tuned_model(\n",
        "    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n",
        "    source_model=base_model.name,\n",
        "    training_data=[\n",
        "        {\n",
        "             'text_input': '1',\n",
        "             'output': '2',\n",
        "        },{\n",
        "             'text_input': '3',\n",
        "             'output': '4',\n",
        "        },{\n",
        "             'text_input': '-3',\n",
        "             'output': '-2',\n",
        "        },{\n",
        "             'text_input': 'twenty two',\n",
        "             'output': 'twenty three',\n",
        "        },{\n",
        "             'text_input': 'two hundred',\n",
        "             'output': 'two hundred one',\n",
        "        },{\n",
        "             'text_input': 'ninety nine',\n",
        "             'output': 'one hundred',\n",
        "        },{\n",
        "             'text_input': '8',\n",
        "             'output': '9',\n",
        "        },{\n",
        "             'text_input': '-98',\n",
        "             'output': '-97',\n",
        "        },{\n",
        "             'text_input': '1,000',\n",
        "             'output': '1,001',\n",
        "        },{\n",
        "             'text_input': '10,100,000',\n",
        "             'output': '10,100,001',\n",
        "        },{\n",
        "             'text_input': 'thirteen',\n",
        "             'output': 'fourteen',\n",
        "        },{\n",
        "             'text_input': 'eighty',\n",
        "             'output': 'eighty one',\n",
        "        },{\n",
        "             'text_input': 'one',\n",
        "             'output': 'two',\n",
        "        },{\n",
        "             'text_input': 'three',\n",
        "             'output': 'four',\n",
        "        },{\n",
        "             'text_input': 'seven',\n",
        "             'output': 'eight',\n",
        "        }\n",
        "    ],\n",
        "    id = name,\n",
        "    epoch_count = 100,\n",
        "    batch_size=4,\n",
        "    learning_rate=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-As7ayWDK1w8"
      },
      "source": [
        "Your tuned model is immediately added to the list of tuned models, but its status is set to \"creating\" while the model is tuned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "su64KgY4Uztj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "b6e28949-6af9-408a-f7f9-2e67ad3109c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TunedModel(name='tunedModels/generate-num-5976',\n",
              "           source_model='models/gemini-1.5-flash-001-tuning',\n",
              "           base_model='models/gemini-1.5-flash-001-tuning',\n",
              "           display_name='',\n",
              "           description='',\n",
              "           temperature=1.0,\n",
              "           top_p=0.95,\n",
              "           top_k=64,\n",
              "           state=<State.CREATING: 1>,\n",
              "           create_time=datetime.datetime(2025, 4, 15, 7, 13, 41, 514557, tzinfo=datetime.timezone.utc),\n",
              "           update_time=datetime.datetime(2025, 4, 15, 7, 13, 41, 514557, tzinfo=datetime.timezone.utc),\n",
              "           tuning_task=TuningTask(start_time=None,\n",
              "                                  complete_time=None,\n",
              "                                  snapshots=[],\n",
              "                                  hyperparameters=Hyperparameters(epoch_count=100,\n",
              "                                                                  batch_size=4,\n",
              "                                                                  learning_rate=0.001)),\n",
              "           reader_project_numbers=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EUodUwZkKPi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016c7f05-8bdb-437c-d2cc-91048d6eb037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<State.CREATING: 1>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8X5vkQv-3_"
      },
      "source": [
        "### Check tuning progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWI-vAh4LJIz"
      },
      "source": [
        "Use `metadata` to check the state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g08vqtxYLMxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfbce1e-df94-4162-d25e-3d39467ecae5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_steps: 375\n",
              "tuned_model: \"tunedModels/generate-num-5976\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "operation.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lQ6gSMgK-kz"
      },
      "source": [
        "Wait for the training to finish using `operation.result()`, or `operation.wait_bar()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOUowIv1HgSE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "787023fd8766447d8002325fa417640d",
            "12b13d4ff4c144b39036d32851db6f58",
            "cfd49a3298a54b609088d0050b7b74cc",
            "6cb7c37de6484fc0af64680e365bff18",
            "1e945c7ce5ef4c40b9c8a7d41fca699c",
            "acf01d82b47e46ed94c00375a7f91397",
            "df43f5eb87fe4490b4f704ae8711f550",
            "888d55966303432286624f0e301ae132",
            "b42c4e22cd5c4a458417639cef42c815",
            "7fa545fe45984aa3bf9ddeea2e9082f0",
            "ab384a67689d41ceadd63c90d08ae28d"
          ]
        },
        "outputId": "ed72b4aa-de41-4d73-9ca4-f16f72614a07"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/375 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "787023fd8766447d8002325fa417640d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for status in operation.wait_bar():\n",
        "  time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cg868HzqOx5"
      },
      "source": [
        "You can cancel your tuning job any time using the `cancel()` method. Uncomment the line below and run the code cell to cancel your job before it finishes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQuJ70_hqJi9"
      },
      "outputs": [],
      "source": [
        "#operation.cancel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqiL0TWDqAPn"
      },
      "source": [
        "Once the tuning is complete, you can view the loss curve from the tuning results. The [loss curve](https://ai.google.dev/gemini-api/docs/model-tuning#recommended_configurations) shows how much the model's predictions deviate from the ideal outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIiG57xWLhP7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "model = operation.result()\n",
        "\n",
        "snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
        "\n",
        "sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkoQTXb1vSBC"
      },
      "source": [
        "## Evaluate your model\n",
        "\n",
        "You can use the `genai.generate_content` method and specify the name of your model to test your model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO0YcuSyxydZ"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwGrrj6hS_x2"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('55')\n",
        "result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSNB2zjTx5SZ"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('123455')\n",
        "result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2YVO-m0Ut9H"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('four')\n",
        "result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2MkTR0uTb6U"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('quatre') # French 4\n",
        "result.text                               # French 5 is \"cinq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OruCW1zETsZw"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('III')    # Roman numeral 3\n",
        "result.text                               # Roman numeral 4 is IV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thDdSuUDUJOx"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('七')  # Japanese 7\n",
        "result.text                            # Japanese 8 is 八!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpIA1IFevQQR"
      },
      "source": [
        "It really seems to have picked up the task despite the limited examples, but \"next\" is a simple concept, see the [tuning guide](https://ai.google.dev/gemini-api/docs/model-tuning) for more guidance on improving performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmuQCbTYwIOx"
      },
      "source": [
        "## Update the description\n",
        "\n",
        "You can update the description of your tuned model any time using the `genai.update_tuned_model` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gAVuXT_wG3x"
      },
      "outputs": [],
      "source": [
        "genai.update_tuned_model(f'tunedModels/{name}', {\"description\":\"This is my model.\"});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-c3YerBxVYs"
      },
      "outputs": [],
      "source": [
        "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "\n",
        "model.description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_TpwvBB4bQ7"
      },
      "source": [
        "## Delete the model\n",
        "\n",
        "You can clean up your tuned model list by deleting models you no longer need. Use the `genai.delete_tuned_model` method to delete a model. If you canceled any tuning jobs, you may want to delete those as their performance may be unpredictable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cepfaUCvVGCo"
      },
      "outputs": [],
      "source": [
        "genai.delete_tuned_model(f'tunedModels/{name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljEssIshYDEr"
      },
      "source": [
        "The model no longer exists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN_bkut_4ayL"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  m = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "  print(m)\n",
        "except Exception as e:\n",
        "  print(f\"{type(e)}: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "python.ipynb",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "787023fd8766447d8002325fa417640d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12b13d4ff4c144b39036d32851db6f58",
              "IPY_MODEL_cfd49a3298a54b609088d0050b7b74cc",
              "IPY_MODEL_6cb7c37de6484fc0af64680e365bff18"
            ],
            "layout": "IPY_MODEL_1e945c7ce5ef4c40b9c8a7d41fca699c"
          }
        },
        "12b13d4ff4c144b39036d32851db6f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf01d82b47e46ed94c00375a7f91397",
            "placeholder": "​",
            "style": "IPY_MODEL_df43f5eb87fe4490b4f704ae8711f550",
            "value": "  0%"
          }
        },
        "cfd49a3298a54b609088d0050b7b74cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888d55966303432286624f0e301ae132",
            "max": 375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b42c4e22cd5c4a458417639cef42c815",
            "value": 0
          }
        },
        "6cb7c37de6484fc0af64680e365bff18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa545fe45984aa3bf9ddeea2e9082f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ab384a67689d41ceadd63c90d08ae28d",
            "value": " 0/375 [00:33&lt;?, ?it/s]"
          }
        },
        "1e945c7ce5ef4c40b9c8a7d41fca699c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf01d82b47e46ed94c00375a7f91397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df43f5eb87fe4490b4f704ae8711f550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "888d55966303432286624f0e301ae132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42c4e22cd5c4a458417639cef42c815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fa545fe45984aa3bf9ddeea2e9082f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab384a67689d41ceadd63c90d08ae28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}